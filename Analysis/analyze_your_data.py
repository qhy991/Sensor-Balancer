#!/usr/bin/env python3
"""
åˆ†ææ‚¨æä¾›çš„ä½ç½®ä¸€è‡´æ€§æ•°æ®
"""

import json
import os
import sys
from consistency_data_analyzer import ConsistencyDataAnalyzer

def load_data_from_json(filepath):
    """ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®æ–‡ä»¶: {filepath}")
        return data
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {filepath}")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSONæ ¼å¼é”™è¯¯: {e}")
        return None
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None

def main():
    """åˆ†ææ‚¨çš„æ•°æ®"""
    print("ğŸ”§ åˆ†æä½ç½®ä¸€è‡´æ€§æ•°æ®")
    print("=" * 60)
    
    # ä»å‘½ä»¤è¡Œå‚æ•°æˆ–é»˜è®¤è·¯å¾„è·å–æ–‡ä»¶è·¯å¾„
    if len(sys.argv) > 1:
        json_filepath = sys.argv[1]
    else:
        # é»˜è®¤æ–‡ä»¶è·¯å¾„
        json_filepath = r"C:\Users\84672\Documents\Research\balance-sensor\consistency-test\0801-2.json"
    
    print(f"ğŸ“ æ•°æ®æ–‡ä»¶è·¯å¾„: {json_filepath}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(json_filepath):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {json_filepath}")
        print("è¯·ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼Œæˆ–é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šæ–‡ä»¶è·¯å¾„")
        return
    
    # åŠ è½½æ•°æ®
    your_data = load_data_from_json(json_filepath)
    if your_data is None:
        return
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = ConsistencyDataAnalyzer(data_dict=your_data)
    
    # è¿è¡Œå®Œæ•´åˆ†æ
    results = analyzer.run_full_analysis("your_analysis_results")
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ‚¨çš„æ•°æ®åˆ†æç»“æœæ‘˜è¦:")
    print("=" * 60)
    print(f"æ•°æ®æœ‰æ•ˆæ€§: {'âœ… é€šè¿‡' if results['is_valid'] else 'âŒ å¤±è´¥'}")
    print(f"æ€»æµ‹é‡ç‚¹: {results['summary']['total_measurements']}")
    print(f"æœ‰æ•ˆæµ‹é‡ç‚¹: {results['summary']['valid_measurements']} ({results['summary']['valid_measurements']/results['summary']['total_measurements']*100:.1f}%)")
    print(f"å¹³å‡æ•æ„Ÿæ€§: {results['summary']['avg_sensitivity']:.6f} Â± {results['summary']['std_sensitivity']:.6f}")
    print(f"å¹³å‡å˜å¼‚ç³»æ•°: {results['summary']['avg_cv']:.3f} Â± {results['summary']['std_cv']:.3f}")
    print(f"ä½ç½®é—´ä¸€è‡´æ€§CV: {results['consistency_analysis']['position_consistency_cv']:.3f}")
    print(f"é—®é¢˜ä½ç½®æ•°: {len(results['problematic_positions'])}")
    
    print(f"\nğŸ“Š å›¾è¡¨æ–‡ä»¶: {results['plot_path']}")
    print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {results['report_path']}")
    
    # ç‰¹åˆ«åˆ†æè´Ÿæ•æ„Ÿæ€§é—®é¢˜
    print("\nğŸ” è´Ÿæ•æ„Ÿæ€§åˆ†æ:")
    negative_count = 0
    total_count = 0
    
    for pos_id, pos_results in your_data['consistency_results'].items():
        for weight_id, result in pos_results.items():
            total_count += 1
            sensitivity = result.get('sensitivity_total', 0)
            if sensitivity < -1e-6:
                negative_count += 1
                pos_name = your_data['guide_positions'][pos_id]['name']
                print(f"   âš ï¸ {pos_name} ç ç {weight_id}: {sensitivity:.6f}")
    
    print(f"   è´Ÿæ•æ„Ÿæ€§æ¯”ä¾‹: {negative_count}/{total_count} ({negative_count/total_count*100:.1f}%)")
    
    if negative_count > 0:
        print("\nğŸ’¡ å…³äºè´Ÿæ•æ„Ÿæ€§çš„å»ºè®®:")
        print("   - è´Ÿæ•æ„Ÿæ€§é€šå¸¸è¡¨ç¤ºåŸºçº¿æ ¡æ­£è¿‡åº¦")
        print("   - å»ºè®®æ£€æŸ¥åŸºçº¿æ•°æ®çš„è®°å½•è¿‡ç¨‹")
        print("   - å¯èƒ½éœ€è¦è°ƒæ•´åŸºçº¿æ ¡æ­£ç®—æ³•")
        print("   - è€ƒè™‘é‡æ–°è¿›è¡ŒåŸºçº¿æµ‹é‡")

if __name__ == "__main__":
    main() 