"""
æ—¶é—´ä¸€è‡´æ€§åˆ†ææ¨¡å—
åˆ†æä¼ æ„Ÿå™¨åœ¨æ—¶é—´ç»´åº¦ä¸Šçš„ä¸ä¸€è‡´æ€§é—®é¢˜
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from PyQt5.QtWidgets import (QWidget, QVBoxLayout, QHBoxLayout, QPushButton, 
                            QLabel, QGroupBox, QTextEdit, QProgressBar, 
                            QSpinBox, QDoubleSpinBox, QCheckBox, QTabWidget,
                            QTableWidget, QTableWidgetItem, QFileDialog, QMessageBox)
from PyQt5.QtCore import QTimer, QThread, pyqtSignal
import pandas as pd
from scipy import signal
from scipy.stats import linregress
from datetime import datetime, timedelta
import json

class TemporalDriftAnalyzer:
    """æ—¶é—´æ¼‚ç§»åˆ†æå™¨"""
    
    def __init__(self):
        self.drift_data = {}  # å­˜å‚¨æ¼‚ç§»æ•°æ®
        self.analysis_results = {}
        
    def analyze_temporal_drift(self, time_series_data, time_stamps):
        """
        åˆ†ææ—¶é—´æ¼‚ç§»
        
        Args:
            time_series_data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå½¢çŠ¶ä¸º (time_points, height, width)
            time_stamps: æ—¶é—´æˆ³åˆ—è¡¨
            
        Returns:
            æ¼‚ç§»åˆ†æç»“æœ
        """
        results = {}
        
        # 1. è®¡ç®—æ¯ä¸ªä¼ æ„Ÿå™¨ç‚¹çš„æ¼‚ç§»ç‡
        drift_rates = self._calculate_drift_rates(time_series_data, time_stamps)
        
        # 2. åˆ†ææ¼‚ç§»æ¨¡å¼
        drift_patterns = self._analyze_drift_patterns(time_series_data, time_stamps)
        
        # 3. æ£€æµ‹å¼‚å¸¸æ¼‚ç§»ç‚¹
        anomaly_points = self._detect_drift_anomalies(time_series_data, time_stamps)
        
        # 4. é¢„æµ‹æœªæ¥æ¼‚ç§»è¶‹åŠ¿
        drift_prediction = self._predict_drift_trend(time_series_data, time_stamps)
        
        results = {
            'drift_rates': drift_rates,
            'drift_patterns': drift_patterns,
            'anomaly_points': anomaly_points,
            'drift_prediction': drift_prediction,
            'summary_stats': self._calculate_drift_summary(drift_rates)
        }
        
        return results
    
    def _calculate_drift_rates(self, time_series_data, time_stamps):
        """è®¡ç®—æ¯ä¸ªä¼ æ„Ÿå™¨ç‚¹çš„æ¼‚ç§»ç‡"""
        height, width = time_series_data.shape[1], time_series_data.shape[2]
        drift_rates = np.zeros((height, width))
        
        # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºæ•°å€¼ï¼ˆç§’ï¼‰
        time_numeric = np.array([(ts - time_stamps[0]).total_seconds() for ts in time_stamps])
        
        for i in range(height):
            for j in range(width):
                # è·å–è¯¥ä¼ æ„Ÿå™¨ç‚¹çš„æ—¶é—´åºåˆ—
                sensor_data = time_series_data[:, i, j]
                
                # ä½¿ç”¨çº¿æ€§å›å½’è®¡ç®—æ¼‚ç§»ç‡
                if len(sensor_data) > 1:
                    slope, intercept, r_value, p_value, std_err = linregress(time_numeric, sensor_data)
                    drift_rates[i, j] = slope  # æ¼‚ç§»ç‡ï¼ˆå•ä½/ç§’ï¼‰
        
        return drift_rates
    
    def _analyze_drift_patterns(self, time_series_data, time_stamps):
        """åˆ†ææ¼‚ç§»æ¨¡å¼"""
        patterns = {}
        
        # 1. çº¿æ€§æ¼‚ç§»æ£€æµ‹
        patterns['linear_drift'] = self._detect_linear_drift(time_series_data, time_stamps)
        
        # 2. å‘¨æœŸæ€§æ¼‚ç§»æ£€æµ‹
        patterns['periodic_drift'] = self._detect_periodic_drift(time_series_data, time_stamps)
        
        # 3. çªå˜ç‚¹æ£€æµ‹
        patterns['change_points'] = self._detect_change_points(time_series_data, time_stamps)
        
        return patterns
    
    def _detect_linear_drift(self, time_series_data, time_stamps):
        """æ£€æµ‹çº¿æ€§æ¼‚ç§»"""
        height, width = time_series_data.shape[1], time_series_data.shape[2]
        linear_drift_mask = np.zeros((height, width), dtype=bool)
        
        time_numeric = np.array([(ts - time_stamps[0]).total_seconds() for ts in time_stamps])
        
        for i in range(height):
            for j in range(width):
                sensor_data = time_series_data[:, i, j]
                
                if len(sensor_data) > 2:
                    slope, intercept, r_value, p_value, std_err = linregress(time_numeric, sensor_data)
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºæ˜¾è‘—çº¿æ€§æ¼‚ç§»
                    if abs(slope) > 1e-6 and p_value < 0.05:  # å¯è°ƒæ•´é˜ˆå€¼
                        linear_drift_mask[i, j] = True
        
        return linear_drift_mask
    
    def _detect_periodic_drift(self, time_series_data, time_stamps):
        """æ£€æµ‹å‘¨æœŸæ€§æ¼‚ç§»"""
        height, width = time_series_data.shape[1], time_series_data.shape[2]
        periodic_drift_mask = np.zeros((height, width), dtype=bool)
        
        for i in range(height):
            for j in range(width):
                sensor_data = time_series_data[:, i, j]
                
                if len(sensor_data) > 10:
                    # ä½¿ç”¨FFTæ£€æµ‹å‘¨æœŸæ€§
                    fft_result = np.fft.fft(sensor_data)
                    power_spectrum = np.abs(fft_result)**2
                    
                    # å¯»æ‰¾ä¸»è¦é¢‘ç‡æˆåˆ†
                    main_freq_idx = np.argmax(power_spectrum[1:len(power_spectrum)//2]) + 1
                    main_power = power_spectrum[main_freq_idx]
                    total_power = np.sum(power_spectrum[1:len(power_spectrum)//2])
                    
                    # å¦‚æœä¸»è¦é¢‘ç‡æˆåˆ†å æ€»åŠŸç‡çš„æ¯”ä¾‹è¶…è¿‡é˜ˆå€¼ï¼Œè®¤ä¸ºå­˜åœ¨å‘¨æœŸæ€§
                    if main_power / total_power > 0.3:  # å¯è°ƒæ•´é˜ˆå€¼
                        periodic_drift_mask[i, j] = True
        
        return periodic_drift_mask
    
    def _detect_change_points(self, time_series_data, time_stamps):
        """æ£€æµ‹çªå˜ç‚¹"""
        height, width = time_series_data.shape[1], time_series_data.shape[2]
        change_points = []
        
        for i in range(height):
            for j in range(width):
                sensor_data = time_series_data[:, i, j]
                
                if len(sensor_data) > 5:
                    # ä½¿ç”¨æ»‘åŠ¨çª—å£æ£€æµ‹çªå˜
                    window_size = min(5, len(sensor_data) // 4)
                    
                    for k in range(window_size, len(sensor_data) - window_size):
                        before_mean = np.mean(sensor_data[k-window_size:k])
                        after_mean = np.mean(sensor_data[k:k+window_size])
                        
                        # å¦‚æœå‰åå‡å€¼å·®å¼‚è¶…è¿‡é˜ˆå€¼ï¼Œè®¤ä¸ºæ˜¯çªå˜ç‚¹
                        if abs(after_mean - before_mean) > np.std(sensor_data) * 2:
                            change_points.append({
                                'position': (i, j),
                                'time_index': k,
                                'time_stamp': time_stamps[k],
                                'magnitude': abs(after_mean - before_mean)
                            })
        
        return change_points
    
    def _detect_drift_anomalies(self, time_series_data, time_stamps):
        """æ£€æµ‹å¼‚å¸¸æ¼‚ç§»ç‚¹"""
        height, width = time_series_data.shape[1], time_series_data.shape[2]
        anomaly_points = []
        
        for i in range(height):
            for j in range(width):
                sensor_data = time_series_data[:, i, j]
                
                if len(sensor_data) > 10:
                    # è®¡ç®—ç»Ÿè®¡å¼‚å¸¸å€¼
                    mean_val = np.mean(sensor_data)
                    std_val = np.std(sensor_data)
                    
                    # æ£€æµ‹3Ïƒå¼‚å¸¸å€¼
                    anomaly_indices = np.where(np.abs(sensor_data - mean_val) > 3 * std_val)[0]
                    
                    for idx in anomaly_indices:
                        anomaly_points.append({
                            'position': (i, j),
                            'time_index': idx,
                            'time_stamp': time_stamps[idx],
                            'value': sensor_data[idx],
                            'deviation': (sensor_data[idx] - mean_val) / std_val
                        })
        
        return anomaly_points
    
    def _predict_drift_trend(self, time_series_data, time_stamps):
        """é¢„æµ‹æ¼‚ç§»è¶‹åŠ¿"""
        height, width = time_series_data.shape[1], time_series_data.shape[2]
        predictions = {}
        
        time_numeric = np.array([(ts - time_stamps[0]).total_seconds() for ts in time_stamps])
        
        for i in range(height):
            for j in range(width):
                sensor_data = time_series_data[:, i, j]
                
                if len(sensor_data) > 5:
                    # çº¿æ€§å›å½’é¢„æµ‹
                    slope, intercept, r_value, p_value, std_err = linregress(time_numeric, sensor_data)
                    
                    # é¢„æµ‹æœªæ¥1å°æ—¶çš„å€¼
                    future_time = time_numeric[-1] + 3600  # 1å°æ—¶å
                    predicted_value = slope * future_time + intercept
                    
                    predictions[(i, j)] = {
                        'current_slope': slope,
                        'predicted_value_1h': predicted_value,
                        'confidence': r_value**2,
                        'prediction_interval': (predicted_value - 2*std_err, predicted_value + 2*std_err)
                    }
        
        return predictions
    
    def _calculate_drift_summary(self, drift_rates):
        """è®¡ç®—æ¼‚ç§»ç»Ÿè®¡æ‘˜è¦"""
        valid_rates = drift_rates[drift_rates != 0]
        
        if len(valid_rates) == 0:
            return {}
        
        summary = {
            'mean_drift_rate': np.mean(valid_rates),
            'std_drift_rate': np.std(valid_rates),
            'max_drift_rate': np.max(valid_rates),
            'min_drift_rate': np.min(valid_rates),
            'drift_range': np.max(valid_rates) - np.min(valid_rates),
            'positive_drift_count': np.sum(valid_rates > 0),
            'negative_drift_count': np.sum(valid_rates < 0),
            'total_sensors': len(valid_rates)
        }
        
        return summary


class ResponseTimeAnalyzer:
    """å“åº”æ—¶é—´åˆ†æå™¨"""
    
    def __init__(self):
        self.response_data = {}
        
    def analyze_response_time(self, time_series_data, time_stamps, pressure_events):
        """
        åˆ†æå“åº”æ—¶é—´
        
        Args:
            time_series_data: æ—¶é—´åºåˆ—æ•°æ®
            time_stamps: æ—¶é—´æˆ³åˆ—è¡¨
            pressure_events: å‹åŠ›äº‹ä»¶åˆ—è¡¨ï¼Œæ¯ä¸ªäº‹ä»¶åŒ…å«å¼€å§‹æ—¶é—´ã€ç»“æŸæ—¶é—´ã€å‹åŠ›å€¼
            
        Returns:
            å“åº”æ—¶é—´åˆ†æç»“æœ
        """
        results = {}
        
        # 1. è®¡ç®—ä¸Šå‡æ—¶é—´
        rise_times = self._calculate_rise_times(time_series_data, time_stamps, pressure_events)
        
        # 2. è®¡ç®—ä¸‹é™æ—¶é—´
        fall_times = self._calculate_fall_times(time_series_data, time_stamps, pressure_events)
        
        # 3. åˆ†æå“åº”ä¸€è‡´æ€§
        response_consistency = self._analyze_response_consistency(rise_times, fall_times)
        
        # 4. æ£€æµ‹å“åº”å¼‚å¸¸
        response_anomalies = self._detect_response_anomalies(time_series_data, time_stamps, pressure_events)
        
        results = {
            'rise_times': rise_times,
            'fall_times': fall_times,
            'response_consistency': response_consistency,
            'response_anomalies': response_anomalies,
            'summary_stats': self._calculate_response_summary(rise_times, fall_times)
        }
        
        return results
    
    def _calculate_rise_times(self, time_series_data, time_stamps, pressure_events):
        """è®¡ç®—ä¸Šå‡æ—¶é—´"""
        height, width = time_series_data.shape[1], time_series_data.shape[2]
        rise_times = {}
        
        for event_idx, event in enumerate(pressure_events):
            # æ‰¾åˆ°äº‹ä»¶å¼€å§‹å’Œç»“æŸçš„æ—¶é—´ç´¢å¼•
            start_idx = self._find_time_index(time_stamps, event['start_time'])
            end_idx = self._find_time_index(time_stamps, event['end_time'])
            
            if start_idx is None or end_idx is None:
                continue
            
            event_rise_times = np.zeros((height, width))
            
            for i in range(height):
                for j in range(width):
                    sensor_data = time_series_data[start_idx:end_idx+1, i, j]
                    
                    if len(sensor_data) > 1:
                        # è®¡ç®—ä»10%åˆ°90%çš„ä¸Šå‡æ—¶é—´
                        rise_time = self._calculate_rise_time_10_90(sensor_data, time_stamps[start_idx:end_idx+1])
                        event_rise_times[i, j] = rise_time
            
            rise_times[f'event_{event_idx}'] = event_rise_times
        
        return rise_times
    
    def _calculate_fall_times(self, time_series_data, time_stamps, pressure_events):
        """è®¡ç®—ä¸‹é™æ—¶é—´"""
        height, width = time_series_data.shape[1], time_series_data.shape[2]
        fall_times = {}
        
        for event_idx, event in enumerate(pressure_events):
            # æ‰¾åˆ°äº‹ä»¶ç»“æŸåçš„æ¢å¤æœŸ
            end_idx = self._find_time_index(time_stamps, event['end_time'])
            recovery_end_idx = min(end_idx + 50, len(time_stamps) - 1)  # å‡è®¾50ä¸ªé‡‡æ ·ç‚¹çš„æ¢å¤æœŸ
            
            if end_idx is None:
                continue
            
            event_fall_times = np.zeros((height, width))
            
            for i in range(height):
                for j in range(width):
                    sensor_data = time_series_data[end_idx:recovery_end_idx+1, i, j]
                    
                    if len(sensor_data) > 1:
                        # è®¡ç®—ä»90%åˆ°10%çš„ä¸‹é™æ—¶é—´
                        fall_time = self._calculate_fall_time_90_10(sensor_data, time_stamps[end_idx:recovery_end_idx+1])
                        event_fall_times[i, j] = fall_time
            
            fall_times[f'event_{event_idx}'] = event_fall_times
        
        return fall_times
    
    def _calculate_rise_time_10_90(self, sensor_data, time_stamps):
        """è®¡ç®—10%-90%ä¸Šå‡æ—¶é—´"""
        if len(sensor_data) < 2:
            return 0.0
        
        # æ‰¾åˆ°10%å’Œ90%çš„å€¼
        min_val = np.min(sensor_data)
        max_val = np.max(sensor_data)
        range_val = max_val - min_val
        
        if range_val == 0:
            return 0.0
        
        threshold_10 = min_val + 0.1 * range_val
        threshold_90 = min_val + 0.9 * range_val
        
        # æ‰¾åˆ°10%å’Œ90%å¯¹åº”çš„æ—¶é—´ç‚¹
        time_10 = None
        time_90 = None
        
        for k, value in enumerate(sensor_data):
            if time_10 is None and value >= threshold_10:
                time_10 = time_stamps[k]
            if time_90 is None and value >= threshold_90:
                time_90 = time_stamps[k]
                break
        
        if time_10 is not None and time_90 is not None:
            return (time_90 - time_10).total_seconds()
        
        return 0.0
    
    def _calculate_fall_time_90_10(self, sensor_data, time_stamps):
        """è®¡ç®—90%-10%ä¸‹é™æ—¶é—´"""
        if len(sensor_data) < 2:
            return 0.0
        
        # æ‰¾åˆ°90%å’Œ10%çš„å€¼
        min_val = np.min(sensor_data)
        max_val = np.max(sensor_data)
        range_val = max_val - min_val
        
        if range_val == 0:
            return 0.0
        
        threshold_90 = min_val + 0.9 * range_val
        threshold_10 = min_val + 0.1 * range_val
        
        # æ‰¾åˆ°90%å’Œ10%å¯¹åº”çš„æ—¶é—´ç‚¹
        time_90 = None
        time_10 = None
        
        for k, value in enumerate(sensor_data):
            if time_90 is None and value <= threshold_90:
                time_90 = time_stamps[k]
            if time_10 is None and value <= threshold_10:
                time_10 = time_stamps[k]
                break
        
        if time_90 is not None and time_10 is not None:
            return (time_10 - time_90).total_seconds()
        
        return 0.0
    
    def _find_time_index(self, time_stamps, target_time):
        """æ‰¾åˆ°æœ€æ¥è¿‘ç›®æ ‡æ—¶é—´çš„æ—¶é—´ç´¢å¼•"""
        if not time_stamps:
            return None
        
        # æ‰¾åˆ°æœ€æ¥è¿‘çš„æ—¶é—´æˆ³
        time_diffs = [abs((ts - target_time).total_seconds()) for ts in time_stamps]
        min_idx = np.argmin(time_diffs)
        
        # å¦‚æœæ—¶é—´å·®å¤ªå¤§ï¼Œè¿”å›None
        if time_diffs[min_idx] > 1.0:  # 1ç§’é˜ˆå€¼
            return None
        
        return min_idx
    
    def _analyze_response_consistency(self, rise_times, fall_times):
        """åˆ†æå“åº”ä¸€è‡´æ€§"""
        consistency = {}
        
        # è®¡ç®—æ‰€æœ‰äº‹ä»¶çš„å“åº”æ—¶é—´ç»Ÿè®¡
        all_rise_times = []
        all_fall_times = []
        
        for event_key in rise_times:
            rise_data = rise_times[event_key]
            fall_data = fall_times[event_key]
            
            valid_rise = rise_data[rise_data > 0]
            valid_fall = fall_data[fall_data > 0]
            
            all_rise_times.extend(valid_rise.flatten())
            all_fall_times.extend(valid_fall.flatten())
        
        if all_rise_times:
            consistency['rise_time_stats'] = {
                'mean': np.mean(all_rise_times),
                'std': np.std(all_rise_times),
                'cv': np.std(all_rise_times) / np.mean(all_rise_times) if np.mean(all_rise_times) > 0 else 0
            }
        
        if all_fall_times:
            consistency['fall_time_stats'] = {
                'mean': np.mean(all_fall_times),
                'std': np.std(all_fall_times),
                'cv': np.std(all_fall_times) / np.mean(all_fall_times) if np.mean(all_fall_times) > 0 else 0
            }
        
        return consistency
    
    def _detect_response_anomalies(self, time_series_data, time_stamps, pressure_events):
        """æ£€æµ‹å“åº”å¼‚å¸¸"""
        anomalies = []
        
        for event_idx, event in enumerate(pressure_events):
            start_idx = self._find_time_index(time_stamps, event['start_time'])
            end_idx = self._find_time_index(time_stamps, event['end_time'])
            
            if start_idx is None or end_idx is None:
                continue
            
            # æ£€æµ‹å“åº”å»¶è¿Ÿ
            for i in range(time_series_data.shape[1]):
                for j in range(time_series_data.shape[2]):
                    sensor_data = time_series_data[start_idx:end_idx+1, i, j]
                    
                    if len(sensor_data) > 5:
                        # æ£€æµ‹å“åº”å»¶è¿Ÿ
                        response_delay = self._detect_response_delay(sensor_data, time_stamps[start_idx:end_idx+1])
                        
                        if response_delay > 0.1:  # 100msé˜ˆå€¼
                            anomalies.append({
                                'type': 'response_delay',
                                'position': (i, j),
                                'event': event_idx,
                                'delay': response_delay,
                                'severity': 'high' if response_delay > 0.5 else 'medium'
                            })
        
        return anomalies
    
    def _detect_response_delay(self, sensor_data, time_stamps):
        """æ£€æµ‹å“åº”å»¶è¿Ÿ"""
        if len(sensor_data) < 2:
            return 0.0
        
        # è®¡ç®—åŸºçº¿å™ªå£°
        baseline = np.mean(sensor_data[:min(5, len(sensor_data)//4)])
        noise_std = np.std(sensor_data[:min(5, len(sensor_data)//4)])
        
        # å¯»æ‰¾å“åº”å¼€å§‹ç‚¹ï¼ˆè¶…è¿‡åŸºçº¿3Ïƒï¼‰
        threshold = baseline + 3 * noise_std
        
        for k, value in enumerate(sensor_data):
            if value > threshold:
                return (time_stamps[k] - time_stamps[0]).total_seconds()
        
        return 0.0
    
    def _calculate_response_summary(self, rise_times, fall_times):
        """è®¡ç®—å“åº”æ—¶é—´ç»Ÿè®¡æ‘˜è¦"""
        summary = {}
        
        # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„å“åº”æ—¶é—´
        all_rise = []
        all_fall = []
        
        for event_key in rise_times:
            rise_data = rise_times[event_key]
            fall_data = fall_times[event_key]
            
            valid_rise = rise_data[rise_data > 0]
            valid_fall = fall_data[fall_data > 0]
            
            all_rise.extend(valid_rise.flatten())
            all_fall.extend(valid_fall.flatten())
        
        if all_rise:
            summary['rise_time_summary'] = {
                'count': len(all_rise),
                'mean': np.mean(all_rise),
                'std': np.std(all_rise),
                'min': np.min(all_rise),
                'max': np.max(all_rise),
                'cv': np.std(all_rise) / np.mean(all_rise) if np.mean(all_rise) > 0 else 0
            }
        
        if all_fall:
            summary['fall_time_summary'] = {
                'count': len(all_fall),
                'mean': np.mean(all_fall),
                'std': np.std(all_fall),
                'min': np.min(all_fall),
                'max': np.max(all_fall),
                'cv': np.std(all_fall) / np.mean(all_fall) if np.mean(all_fall) > 0 else 0
            }
        
        return summary


class FatigueAnalyzer:
    """ç–²åŠ³æ•ˆåº”åˆ†æå™¨"""
    
    def __init__(self):
        self.fatigue_data = {}
        
    def analyze_fatigue_effects(self, repeated_test_data, test_cycles):
        """
        åˆ†æç–²åŠ³æ•ˆåº”
        
        Args:
            repeated_test_data: é‡å¤æµ‹è¯•æ•°æ®ï¼Œå½¢çŠ¶ä¸º (cycles, time_points, height, width)
            test_cycles: æµ‹è¯•å‘¨æœŸä¿¡æ¯
            
        Returns:
            ç–²åŠ³æ•ˆåº”åˆ†æç»“æœ
        """
        results = {}
        
        # 1. åˆ†ææ•æ„Ÿåº¦è¡°å‡
        sensitivity_decay = self._analyze_sensitivity_decay(repeated_test_data, test_cycles)
        
        # 2. åˆ†æå“åº”ç¨³å®šæ€§å˜åŒ–
        stability_changes = self._analyze_stability_changes(repeated_test_data, test_cycles)
        
        # 3. æ£€æµ‹ç–²åŠ³é˜ˆå€¼
        fatigue_thresholds = self._detect_fatigue_thresholds(repeated_test_data, test_cycles)
        
        # 4. é¢„æµ‹ç–²åŠ³å¯¿å‘½
        fatigue_life_prediction = self._predict_fatigue_life(repeated_test_data, test_cycles)
        
        results = {
            'sensitivity_decay': sensitivity_decay,
            'stability_changes': stability_changes,
            'fatigue_thresholds': fatigue_thresholds,
            'fatigue_life_prediction': fatigue_life_prediction,
            'summary_stats': self._calculate_fatigue_summary(sensitivity_decay, stability_changes)
        }
        
        return results
    
    def _analyze_sensitivity_decay(self, repeated_test_data, test_cycles):
        """åˆ†ææ•æ„Ÿåº¦è¡°å‡"""
        num_cycles, time_points, height, width = repeated_test_data.shape
        sensitivity_decay = {}
        
        for i in range(height):
            for j in range(width):
                # è®¡ç®—æ¯ä¸ªå‘¨æœŸçš„å³°å€¼å“åº”
                peak_responses = []
                
                for cycle in range(num_cycles):
                    cycle_data = repeated_test_data[cycle, :, i, j]
                    peak_response = np.max(cycle_data)
                    peak_responses.append(peak_response)
                
                # åˆ†ææ•æ„Ÿåº¦è¡°å‡è¶‹åŠ¿
                if len(peak_responses) > 1:
                    # è®¡ç®—è¡°å‡ç‡
                    initial_sensitivity = peak_responses[0]
                    final_sensitivity = peak_responses[-1]
                    decay_rate = (initial_sensitivity - final_sensitivity) / initial_sensitivity
                    
                    # æ‹Ÿåˆè¡°å‡æ›²çº¿
                    cycles = np.arange(len(peak_responses))
                    if len(cycles) > 2:
                        slope, intercept, r_value, p_value, std_err = linregress(cycles, peak_responses)
                        
                        sensitivity_decay[(i, j)] = {
                            'initial_sensitivity': initial_sensitivity,
                            'final_sensitivity': final_sensitivity,
                            'decay_rate': decay_rate,
                            'decay_slope': slope,
                            'decay_confidence': r_value**2,
                            'peak_responses': peak_responses
                        }
        
        return sensitivity_decay
    
    def _analyze_stability_changes(self, repeated_test_data, test_cycles):
        """åˆ†æå“åº”ç¨³å®šæ€§å˜åŒ–"""
        num_cycles, time_points, height, width = repeated_test_data.shape
        stability_changes = {}
        
        for i in range(height):
            for j in range(width):
                # è®¡ç®—æ¯ä¸ªå‘¨æœŸçš„å“åº”ç¨³å®šæ€§æŒ‡æ ‡
                stability_metrics = []
                
                for cycle in range(num_cycles):
                    cycle_data = repeated_test_data[cycle, :, i, j]
                    
                    # è®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡ï¼ˆæ ‡å‡†å·®/å‡å€¼ï¼‰
                    mean_response = np.mean(cycle_data)
                    std_response = np.std(cycle_data)
                    
                    if mean_response > 0:
                        stability_coefficient = std_response / mean_response
                        stability_metrics.append(stability_coefficient)
                
                # åˆ†æç¨³å®šæ€§å˜åŒ–è¶‹åŠ¿
                if len(stability_metrics) > 1:
                    cycles = np.arange(len(stability_metrics))
                    slope, intercept, r_value, p_value, std_err = linregress(cycles, stability_metrics)
                    
                    stability_changes[(i, j)] = {
                        'initial_stability': stability_metrics[0],
                        'final_stability': stability_metrics[-1],
                        'stability_trend': slope,
                        'stability_confidence': r_value**2,
                        'stability_metrics': stability_metrics
                    }
        
        return stability_changes
    
    def _detect_fatigue_thresholds(self, repeated_test_data, test_cycles):
        """æ£€æµ‹ç–²åŠ³é˜ˆå€¼"""
        num_cycles, time_points, height, width = repeated_test_data.shape
        fatigue_thresholds = {}
        
        for i in range(height):
            for j in range(width):
                # è®¡ç®—æ¯ä¸ªå‘¨æœŸçš„å³°å€¼å“åº”
                peak_responses = []
                
                for cycle in range(num_cycles):
                    cycle_data = repeated_test_data[cycle, :, i, j]
                    peak_response = np.max(cycle_data)
                    peak_responses.append(peak_response)
                
                # æ£€æµ‹ç–²åŠ³é˜ˆå€¼ï¼ˆå“åº”ä¸‹é™è¶…è¿‡10%çš„å‘¨æœŸï¼‰
                if len(peak_responses) > 1:
                    initial_response = peak_responses[0]
                    fatigue_threshold_cycle = None
                    
                    for cycle, response in enumerate(peak_responses):
                        if response < initial_response * 0.9:  # 10%ä¸‹é™é˜ˆå€¼
                            fatigue_threshold_cycle = cycle
                            break
                    
                    if fatigue_threshold_cycle is not None:
                        fatigue_thresholds[(i, j)] = {
                            'threshold_cycle': fatigue_threshold_cycle,
                            'threshold_response': peak_responses[fatigue_threshold_cycle],
                            'initial_response': initial_response,
                            'response_decline': (initial_response - peak_responses[fatigue_threshold_cycle]) / initial_response
                        }
        
        return fatigue_thresholds
    
    def _predict_fatigue_life(self, repeated_test_data, test_cycles):
        """é¢„æµ‹ç–²åŠ³å¯¿å‘½"""
        num_cycles, time_points, height, width = repeated_test_data.shape
        fatigue_life_prediction = {}
        
        for i in range(height):
            for j in range(width):
                # è®¡ç®—æ¯ä¸ªå‘¨æœŸçš„å³°å€¼å“åº”
                peak_responses = []
                
                for cycle in range(num_cycles):
                    cycle_data = repeated_test_data[cycle, :, i, j]
                    peak_response = np.max(cycle_data)
                    peak_responses.append(peak_response)
                
                # é¢„æµ‹ç–²åŠ³å¯¿å‘½
                if len(peak_responses) > 2:
                    cycles = np.arange(len(peak_responses))
                    
                    # æ‹Ÿåˆè¡°å‡æ›²çº¿
                    slope, intercept, r_value, p_value, std_err = linregress(cycles, peak_responses)
                    
                    if slope < 0:  # åªæœ‰åœ¨è¡°å‡æ—¶æ‰é¢„æµ‹
                        initial_response = peak_responses[0]
                        failure_threshold = initial_response * 0.5  # 50%ä¸‹é™ä½œä¸ºå¤±æ•ˆæ ‡å‡†
                        
                        # é¢„æµ‹è¾¾åˆ°å¤±æ•ˆé˜ˆå€¼çš„å‘¨æœŸæ•°
                        if slope != 0:
                            failure_cycle = (failure_threshold - intercept) / slope
                            failure_cycle = max(0, failure_cycle)
                            
                            fatigue_life_prediction[(i, j)] = {
                                'predicted_life_cycles': failure_cycle,
                                'confidence': r_value**2,
                                'decay_rate': abs(slope),
                                'current_cycles': len(peak_responses)
                            }
        
        return fatigue_life_prediction
    
    def _calculate_fatigue_summary(self, sensitivity_decay, stability_changes):
        """è®¡ç®—ç–²åŠ³æ•ˆåº”ç»Ÿè®¡æ‘˜è¦"""
        summary = {}
        
        # æ•æ„Ÿåº¦è¡°å‡ç»Ÿè®¡
        if sensitivity_decay:
            decay_rates = [data['decay_rate'] for data in sensitivity_decay.values()]
            summary['sensitivity_decay_summary'] = {
                'affected_sensors': len(decay_rates),
                'mean_decay_rate': np.mean(decay_rates),
                'max_decay_rate': np.max(decay_rates),
                'severe_decay_count': len([r for r in decay_rates if r > 0.2])
            }
        
        # ç¨³å®šæ€§å˜åŒ–ç»Ÿè®¡
        if stability_changes:
            stability_trends = [data['stability_trend'] for data in stability_changes.values()]
            summary['stability_changes_summary'] = {
                'affected_sensors': len(stability_trends),
                'mean_stability_trend': np.mean(stability_trends),
                'worsening_stability_count': len([t for t in stability_trends if t > 0])
            }
        
        return summary


class TemporalConsistencyWidget(QWidget):
    """æ—¶é—´ä¸€è‡´æ€§åˆ†æç•Œé¢"""
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.drift_analyzer = TemporalDriftAnalyzer()
        self.response_analyzer = ResponseTimeAnalyzer()
        self.fatigue_analyzer = FatigueAnalyzer()
        
        self.time_series_data = None
        self.time_stamps = []
        self.pressure_events = []
        
        self.init_ui()
        
    def init_ui(self):
        """åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢"""
        layout = QVBoxLayout()
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        self.tab_widget = QTabWidget()
        
        # æ—¶é—´æ¼‚ç§»åˆ†ææ ‡ç­¾é¡µ
        self.drift_tab = self.create_drift_tab()
        self.tab_widget.addTab(self.drift_tab, "æ—¶é—´æ¼‚ç§»åˆ†æ")
        
        # å“åº”æ—¶é—´åˆ†ææ ‡ç­¾é¡µ
        self.response_tab = self.create_response_tab()
        self.tab_widget.addTab(self.response_tab, "å“åº”æ—¶é—´åˆ†æ")
        
        # ç–²åŠ³æ•ˆåº”åˆ†ææ ‡ç­¾é¡µ
        self.fatigue_tab = self.create_fatigue_tab()
        self.tab_widget.addTab(self.fatigue_tab, "ç–²åŠ³æ•ˆåº”åˆ†æ")
        
        layout.addWidget(self.tab_widget)
        
        # æ§åˆ¶æŒ‰é’®
        button_layout = QHBoxLayout()
        
        self.start_analysis_btn = QPushButton("å¼€å§‹æ—¶é—´åˆ†æ")
        self.start_analysis_btn.clicked.connect(self.start_temporal_analysis)
        
        self.save_results_btn = QPushButton("ä¿å­˜åˆ†æç»“æœ")
        self.save_results_btn.clicked.connect(self.save_analysis_results)
        self.save_results_btn.setEnabled(False)
        
        self.clear_data_btn = QPushButton("æ¸…ç©ºæ•°æ®")
        self.clear_data_btn.clicked.connect(self.clear_data)
        
        button_layout.addWidget(self.start_analysis_btn)
        button_layout.addWidget(self.save_results_btn)
        button_layout.addWidget(self.clear_data_btn)
        button_layout.addStretch()
        
        layout.addLayout(button_layout)
        
        self.setLayout(layout)
        
    def create_drift_tab(self):
        """åˆ›å»ºæ—¶é—´æ¼‚ç§»åˆ†ææ ‡ç­¾é¡µ"""
        tab = QWidget()
        layout = QVBoxLayout()
        
        # æ§åˆ¶ç»„
        control_group = QGroupBox("æ¼‚ç§»åˆ†ææ§åˆ¶")
        control_layout = QHBoxLayout()
        
        self.drift_duration_spin = QSpinBox()
        self.drift_duration_spin.setRange(1, 24)
        self.drift_duration_spin.setValue(2)
        self.drift_duration_spin.setSuffix(" å°æ—¶")
        
        self.start_drift_analysis_btn = QPushButton("å¼€å§‹æ¼‚ç§»ç›‘æµ‹")
        self.start_drift_analysis_btn.clicked.connect(self.start_drift_monitoring)
        
        self.stop_drift_analysis_btn = QPushButton("åœæ­¢ç›‘æµ‹")
        self.stop_drift_analysis_btn.clicked.connect(self.stop_drift_monitoring)
        self.stop_drift_analysis_btn.setEnabled(False)
        
        control_layout.addWidget(QLabel("ç›‘æµ‹æ—¶é•¿:"))
        control_layout.addWidget(self.drift_duration_spin)
        control_layout.addWidget(self.start_drift_analysis_btn)
        control_layout.addWidget(self.stop_drift_analysis_btn)
        control_layout.addStretch()
        
        control_group.setLayout(control_layout)
        layout.addWidget(control_group)
        
        # ç»“æœæ˜¾ç¤º
        results_group = QGroupBox("æ¼‚ç§»åˆ†æç»“æœ")
        results_layout = QVBoxLayout()
        
        self.drift_results_text = QTextEdit()
        self.drift_results_text.setReadOnly(True)
        
        results_layout.addWidget(self.drift_results_text)
        results_group.setLayout(results_layout)
        layout.addWidget(results_group)
        
        tab.setLayout(layout)
        return tab
    
    def create_response_tab(self):
        """åˆ›å»ºå“åº”æ—¶é—´åˆ†ææ ‡ç­¾é¡µ"""
        tab = QWidget()
        layout = QVBoxLayout()
        
        # æ§åˆ¶ç»„
        control_group = QGroupBox("å“åº”æ—¶é—´åˆ†ææ§åˆ¶")
        control_layout = QHBoxLayout()
        
        self.response_test_count_spin = QSpinBox()
        self.response_test_count_spin.setRange(1, 50)
        self.response_test_count_spin.setValue(10)
        self.response_test_count_spin.setSuffix(" æ¬¡")
        
        self.start_response_test_btn = QPushButton("å¼€å§‹å“åº”æµ‹è¯•")
        self.start_response_test_btn.clicked.connect(self.start_response_test)
        
        self.stop_response_test_btn = QPushButton("åœæ­¢æµ‹è¯•")
        self.stop_response_test_btn.clicked.connect(self.stop_response_test)
        self.stop_response_test_btn.setEnabled(False)
        
        control_layout.addWidget(QLabel("æµ‹è¯•æ¬¡æ•°:"))
        control_layout.addWidget(self.response_test_count_spin)
        control_layout.addWidget(self.start_response_test_btn)
        control_layout.addWidget(self.stop_response_test_btn)
        control_layout.addStretch()
        
        control_group.setLayout(control_layout)
        layout.addWidget(control_group)
        
        # ç»“æœæ˜¾ç¤º
        results_group = QGroupBox("å“åº”æ—¶é—´åˆ†æç»“æœ")
        results_layout = QVBoxLayout()
        
        self.response_results_text = QTextEdit()
        self.response_results_text.setReadOnly(True)
        
        results_layout.addWidget(self.response_results_text)
        results_group.setLayout(results_layout)
        layout.addWidget(results_group)
        
        tab.setLayout(layout)
        return tab
    
    def create_fatigue_tab(self):
        """åˆ›å»ºç–²åŠ³æ•ˆåº”åˆ†ææ ‡ç­¾é¡µ"""
        tab = QWidget()
        layout = QVBoxLayout()
        
        # æ§åˆ¶ç»„
        control_group = QGroupBox("ç–²åŠ³æ•ˆåº”åˆ†ææ§åˆ¶")
        control_layout = QHBoxLayout()
        
        self.fatigue_cycles_spin = QSpinBox()
        self.fatigue_cycles_spin.setRange(10, 1000)
        self.fatigue_cycles_spin.setValue(100)
        self.fatigue_cycles_spin.setSuffix(" æ¬¡")
        
        self.start_fatigue_test_btn = QPushButton("å¼€å§‹ç–²åŠ³æµ‹è¯•")
        self.start_fatigue_test_btn.clicked.connect(self.start_fatigue_test)
        
        self.stop_fatigue_test_btn = QPushButton("åœæ­¢æµ‹è¯•")
        self.stop_fatigue_test_btn.clicked.connect(self.stop_fatigue_test)
        self.stop_fatigue_test_btn.setEnabled(False)
        
        control_layout.addWidget(QLabel("æµ‹è¯•å‘¨æœŸ:"))
        control_layout.addWidget(self.fatigue_cycles_spin)
        control_layout.addWidget(self.start_fatigue_test_btn)
        control_layout.addWidget(self.stop_fatigue_test_btn)
        control_layout.addStretch()
        
        control_group.setLayout(control_layout)
        layout.addWidget(control_group)
        
        # ç»“æœæ˜¾ç¤º
        results_group = QGroupBox("ç–²åŠ³æ•ˆåº”åˆ†æç»“æœ")
        results_layout = QVBoxLayout()
        
        self.fatigue_results_text = QTextEdit()
        self.fatigue_results_text.setReadOnly(True)
        
        results_layout.addWidget(self.fatigue_results_text)
        results_group.setLayout(results_layout)
        layout.addWidget(results_group)
        
        tab.setLayout(layout)
        return tab
    
    def start_temporal_analysis(self):
        """å¼€å§‹æ—¶é—´ä¸€è‡´æ€§åˆ†æ"""
        if self.time_series_data is None:
            QMessageBox.warning(self, "è­¦å‘Š", "æ²¡æœ‰æ—¶é—´åºåˆ—æ•°æ®")
            return
        
        try:
            # æ‰§è¡Œæ—¶é—´æ¼‚ç§»åˆ†æ
            drift_results = self.drift_analyzer.analyze_temporal_drift(
                self.time_series_data, self.time_stamps
            )
            
            # æ‰§è¡Œå“åº”æ—¶é—´åˆ†æ
            response_results = self.response_analyzer.analyze_response_time(
                self.time_series_data, self.time_stamps, self.pressure_events
            )
            
            # æ˜¾ç¤ºåˆ†æç»“æœ
            self.display_drift_results(drift_results)
            self.display_response_results(response_results)
            
            self.save_results_btn.setEnabled(True)
            
        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"åˆ†æå¤±è´¥: {e}")
    
    def display_drift_results(self, results):
        """æ˜¾ç¤ºæ¼‚ç§»åˆ†æç»“æœ"""
        if not results:
            return
        
        summary = results.get('summary_stats', {})
        
        result_text = f"""
=== æ—¶é—´æ¼‚ç§»åˆ†æç»“æœ ===
åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š æ¼‚ç§»ç»Ÿè®¡:
"""
        
        if summary:
            result_text += f"""
â€¢ å¹³å‡æ¼‚ç§»ç‡: {summary.get('mean_drift_rate', 0):.6f} å•ä½/ç§’
â€¢ æ¼‚ç§»ç‡æ ‡å‡†å·®: {summary.get('std_drift_rate', 0):.6f}
â€¢ æœ€å¤§æ¼‚ç§»ç‡: {summary.get('max_drift_rate', 0):.6f}
â€¢ æœ€å°æ¼‚ç§»ç‡: {summary.get('min_drift_rate', 0):.6f}
â€¢ æ¼‚ç§»èŒƒå›´: {summary.get('drift_range', 0):.6f}
â€¢ æ­£æ¼‚ç§»ä¼ æ„Ÿå™¨: {summary.get('positive_drift_count', 0)}
â€¢ è´Ÿæ¼‚ç§»ä¼ æ„Ÿå™¨: {summary.get('negative_drift_count', 0)}
â€¢ æ€»ä¼ æ„Ÿå™¨æ•°: {summary.get('total_sensors', 0)}
"""
        
        # æ·»åŠ æ¼‚ç§»æ¨¡å¼ä¿¡æ¯
        patterns = results.get('drift_patterns', {})
        if patterns.get('linear_drift') is not None:
            linear_count = np.sum(patterns['linear_drift'])
            result_text += f"\nâ€¢ çº¿æ€§æ¼‚ç§»ä¼ æ„Ÿå™¨: {linear_count}"
        
        if patterns.get('periodic_drift') is not None:
            periodic_count = np.sum(patterns['periodic_drift'])
            result_text += f"\nâ€¢ å‘¨æœŸæ€§æ¼‚ç§»ä¼ æ„Ÿå™¨: {periodic_count}"
        
        # æ·»åŠ å¼‚å¸¸ç‚¹ä¿¡æ¯
        anomalies = results.get('anomaly_points', [])
        if anomalies:
            result_text += f"\nâ€¢ æ£€æµ‹åˆ°å¼‚å¸¸ç‚¹: {len(anomalies)} ä¸ª"
        
        self.drift_results_text.setText(result_text)
    
    def display_response_results(self, results):
        """æ˜¾ç¤ºå“åº”æ—¶é—´åˆ†æç»“æœ"""
        if not results:
            return
        
        summary = results.get('summary_stats', {})
        
        result_text = f"""
=== å“åº”æ—¶é—´åˆ†æç»“æœ ===
åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š å“åº”æ—¶é—´ç»Ÿè®¡:
"""
        
        rise_summary = summary.get('rise_time_summary', {})
        fall_summary = summary.get('fall_time_summary', {})
        
        if rise_summary:
            result_text += f"""
ä¸Šå‡æ—¶é—´ç»Ÿè®¡:
â€¢ æµ‹è¯•æ¬¡æ•°: {rise_summary.get('count', 0)}
â€¢ å¹³å‡ä¸Šå‡æ—¶é—´: {rise_summary.get('mean', 0):.3f} ç§’
â€¢ ä¸Šå‡æ—¶é—´æ ‡å‡†å·®: {rise_summary.get('std', 0):.3f} ç§’
â€¢ ä¸Šå‡æ—¶é—´èŒƒå›´: {rise_summary.get('min', 0):.3f} - {rise_summary.get('max', 0):.3f} ç§’
â€¢ ä¸Šå‡æ—¶é—´å˜å¼‚ç³»æ•°: {rise_summary.get('cv', 0)*100:.1f}%
"""
        
        if fall_summary:
            result_text += f"""
ä¸‹é™æ—¶é—´ç»Ÿè®¡:
â€¢ æµ‹è¯•æ¬¡æ•°: {fall_summary.get('count', 0)}
â€¢ å¹³å‡ä¸‹é™æ—¶é—´: {fall_summary.get('mean', 0):.3f} ç§’
â€¢ ä¸‹é™æ—¶é—´æ ‡å‡†å·®: {fall_summary.get('std', 0):.3f} ç§’
â€¢ ä¸‹é™æ—¶é—´èŒƒå›´: {fall_summary.get('min', 0):.3f} - {fall_summary.get('max', 0):.3f} ç§’
â€¢ ä¸‹é™æ—¶é—´å˜å¼‚ç³»æ•°: {fall_summary.get('cv', 0)*100:.1f}%
"""
        
        # æ·»åŠ å“åº”ä¸€è‡´æ€§ä¿¡æ¯
        consistency = results.get('response_consistency', {})
        if consistency:
            result_text += f"\nå“åº”ä¸€è‡´æ€§è¯„ä¼°:\n"
            
            rise_stats = consistency.get('rise_time_stats', {})
            if rise_stats:
                result_text += f"â€¢ ä¸Šå‡æ—¶é—´ä¸€è‡´æ€§: {rise_stats.get('cv', 0)*100:.1f}%\n"
            
            fall_stats = consistency.get('fall_time_stats', {})
            if fall_stats:
                result_text += f"â€¢ ä¸‹é™æ—¶é—´ä¸€è‡´æ€§: {fall_stats.get('cv', 0)*100:.1f}%\n"
        
        # æ·»åŠ å¼‚å¸¸ä¿¡æ¯
        anomalies = results.get('response_anomalies', [])
        if anomalies:
            result_text += f"\nâ€¢ æ£€æµ‹åˆ°å“åº”å¼‚å¸¸: {len(anomalies)} ä¸ª"
        
        self.response_results_text.setText(result_text)
    
    def display_fatigue_results(self, results):
        """æ˜¾ç¤ºç–²åŠ³æ•ˆåº”åˆ†æç»“æœ"""
        if not results:
            return
        
        summary = results.get('summary_stats', {})
        
        result_text = f"""
=== ç–²åŠ³æ•ˆåº”åˆ†æç»“æœ ===
åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š ç–²åŠ³æ•ˆåº”ç»Ÿè®¡:
"""
        
        sensitivity_summary = summary.get('sensitivity_decay_summary', {})
        stability_summary = summary.get('stability_changes_summary', {})
        
        if sensitivity_summary:
            result_text += f"""
æ•æ„Ÿåº¦è¡°å‡ç»Ÿè®¡:
â€¢ å—å½±å“ä¼ æ„Ÿå™¨: {sensitivity_summary.get('affected_sensors', 0)}
â€¢ å¹³å‡è¡°å‡ç‡: {sensitivity_summary.get('mean_decay_rate', 0)*100:.1f}%
â€¢ æœ€å¤§è¡°å‡ç‡: {sensitivity_summary.get('max_decay_rate', 0)*100:.1f}%
â€¢ ä¸¥é‡è¡°å‡ä¼ æ„Ÿå™¨: {sensitivity_summary.get('severe_decay_count', 0)}
"""
        
        if stability_summary:
            result_text += f"""
ç¨³å®šæ€§å˜åŒ–ç»Ÿè®¡:
â€¢ å—å½±å“ä¼ æ„Ÿå™¨: {stability_summary.get('affected_sensors', 0)}
â€¢ å¹³å‡ç¨³å®šæ€§è¶‹åŠ¿: {stability_summary.get('mean_stability_trend', 0):.4f}
â€¢ ç¨³å®šæ€§æ¶åŒ–ä¼ æ„Ÿå™¨: {stability_summary.get('worsening_stability_count', 0)}
"""
        
        self.fatigue_results_text.setText(result_text)
    
    def start_drift_monitoring(self):
        """å¼€å§‹æ—¶é—´æ¼‚ç§»ç›‘æµ‹"""
        duration_hours = self.drift_duration_spin.value()
        self.start_drift_analysis_btn.setEnabled(False)
        self.stop_drift_analysis_btn.setEnabled(True)
        
        # åˆå§‹åŒ–æ•°æ®æ”¶é›†
        self.time_series_data = []
        self.time_stamps = []
        
        # å¯åŠ¨å®šæ—¶å™¨æ”¶é›†æ•°æ®
        self.drift_timer = QTimer()
        self.drift_timer.timeout.connect(self.collect_drift_data)
        self.drift_timer.start(1000)  # æ¯ç§’æ”¶é›†ä¸€æ¬¡æ•°æ®
        
        # è®¾ç½®åœæ­¢æ—¶é—´
        self.drift_end_time = datetime.now() + timedelta(hours=duration_hours)
        
        self.drift_results_text.setText(f"å¼€å§‹æ—¶é—´æ¼‚ç§»ç›‘æµ‹...\nç›‘æµ‹æ—¶é•¿: {duration_hours} å°æ—¶\nå¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    def stop_drift_monitoring(self):
        """åœæ­¢æ—¶é—´æ¼‚ç§»ç›‘æµ‹"""
        if hasattr(self, 'drift_timer'):
            self.drift_timer.stop()
        
        self.start_drift_analysis_btn.setEnabled(True)
        self.stop_drift_analysis_btn.setEnabled(False)
        
        # æ‰§è¡Œæ¼‚ç§»åˆ†æ
        if self.time_series_data and len(self.time_series_data) > 10:
            time_series_array = np.array(self.time_series_data)
            drift_results = self.drift_analyzer.analyze_temporal_drift(time_series_array, self.time_stamps)
            self.display_drift_results(drift_results)
        else:
            self.drift_results_text.setText("æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œæ¼‚ç§»åˆ†æ")
    
    def collect_drift_data(self):
        """æ”¶é›†æ¼‚ç§»æ•°æ®"""
        # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾åœæ­¢æ—¶é—´
        if datetime.now() >= self.drift_end_time:
            self.stop_drift_monitoring()
            return
        
        # è·å–å½“å‰ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆè¿™é‡Œéœ€è¦ä»ä¸»ç•Œé¢è·å–ï¼‰
        if hasattr(self.parent(), 'get_current_sensor_data'):
            current_data = self.parent().get_current_sensor_data()
            if current_data is not None:
                self.time_series_data.append(current_data.copy())
                self.time_stamps.append(datetime.now())
        
        # æ›´æ–°çŠ¶æ€
        elapsed_time = datetime.now() - (self.drift_end_time - timedelta(hours=self.drift_duration_spin.value()))
        remaining_time = self.drift_end_time - datetime.now()
        
        status_text = f"ç›‘æµ‹è¿›è¡Œä¸­...\nå·²æ”¶é›†æ•°æ®: {len(self.time_series_data)} ä¸ª\nå·²ç”¨æ—¶é—´: {elapsed_time}\nå‰©ä½™æ—¶é—´: {remaining_time}"
        self.drift_results_text.setText(status_text)
    
    def start_response_test(self):
        """å¼€å§‹å“åº”æ—¶é—´æµ‹è¯•"""
        test_count = self.response_test_count_spin.value()
        self.start_response_test_btn.setEnabled(False)
        self.stop_response_test_btn.setEnabled(True)
        
        # åˆå§‹åŒ–æµ‹è¯•æ•°æ®
        self.pressure_events = []
        self.response_test_data = []
        self.response_test_timestamps = []
        
        # å¯åŠ¨å“åº”æµ‹è¯•
        self.response_test_timer = QTimer()
        self.response_test_timer.timeout.connect(self.perform_response_test)
        self.response_test_timer.start(2000)  # æ¯2ç§’è¿›è¡Œä¸€æ¬¡æµ‹è¯•
        
        self.current_test_count = 0
        self.max_test_count = test_count
        
        self.response_results_text.setText(f"å¼€å§‹å“åº”æ—¶é—´æµ‹è¯•...\næµ‹è¯•æ¬¡æ•°: {test_count}\nå¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    def stop_response_test(self):
        """åœæ­¢å“åº”æ—¶é—´æµ‹è¯•"""
        if hasattr(self, 'response_test_timer'):
            self.response_test_timer.stop()
        
        self.start_response_test_btn.setEnabled(True)
        self.stop_response_test_btn.setEnabled(False)
        
        # æ‰§è¡Œå“åº”æ—¶é—´åˆ†æ
        if self.response_test_data and len(self.response_test_data) > 5:
            response_array = np.array(self.response_test_data)
            response_results = self.response_analyzer.analyze_response_time(
                response_array, self.response_test_timestamps, self.pressure_events
            )
            self.display_response_results(response_results)
        else:
            self.response_results_text.setText("æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå“åº”æ—¶é—´åˆ†æ")
    
    def perform_response_test(self):
        """æ‰§è¡Œå“åº”æ—¶é—´æµ‹è¯•"""
        if self.current_test_count >= self.max_test_count:
            self.stop_response_test()
            return
        
        # è®°å½•æµ‹è¯•å¼€å§‹æ—¶é—´
        test_start_time = datetime.now()
        
        # æ¨¡æ‹Ÿå‹åŠ›äº‹ä»¶ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥ç”±ç”¨æˆ·è§¦å‘æˆ–è‡ªåŠ¨è§¦å‘ï¼‰
        pressure_event = {
            'start_time': test_start_time,
            'end_time': test_start_time + timedelta(seconds=1),
            'pressure_value': 0.5
        }
        self.pressure_events.append(pressure_event)
        
        # æ”¶é›†å“åº”æ•°æ®
        self.collect_response_data(test_start_time, test_start_time + timedelta(seconds=2))
        
        self.current_test_count += 1
        
        # æ›´æ–°çŠ¶æ€
        status_text = f"å“åº”æµ‹è¯•è¿›è¡Œä¸­...\nå·²å®Œæˆ: {self.current_test_count}/{self.max_test_count}\nå½“å‰æµ‹è¯•: {test_start_time.strftime('%H:%M:%S')}"
        self.response_results_text.setText(status_text)
    
    def collect_response_data(self, start_time, end_time):
        """æ”¶é›†å“åº”æ•°æ®"""
        # æ¨¡æ‹Ÿæ”¶é›†2ç§’çš„å“åº”æ•°æ®
        data_points = []
        timestamps = []
        
        current_time = start_time
        while current_time <= end_time:
            # è·å–å½“å‰ä¼ æ„Ÿå™¨æ•°æ®
            if hasattr(self.parent(), 'get_current_sensor_data'):
                current_data = self.parent().get_current_sensor_data()
                if current_data is not None:
                    data_points.append(current_data.copy())
                    timestamps.append(current_time)
            
            current_time += timedelta(milliseconds=50)  # 50msé‡‡æ ·é—´éš”
        
        if data_points:
            self.response_test_data.extend(data_points)
            self.response_test_timestamps.extend(timestamps)
    
    def start_fatigue_test(self):
        """å¼€å§‹ç–²åŠ³æ•ˆåº”æµ‹è¯•"""
        test_cycles = self.fatigue_cycles_spin.value()
        self.start_fatigue_test_btn.setEnabled(False)
        self.stop_fatigue_test_btn.setEnabled(True)
        
        # åˆå§‹åŒ–ç–²åŠ³æµ‹è¯•æ•°æ®
        self.fatigue_test_data = []
        self.fatigue_cycle_data = []
        self.current_fatigue_cycle = 0
        self.max_fatigue_cycles = test_cycles
        
        # å¯åŠ¨ç–²åŠ³æµ‹è¯•
        self.fatigue_test_timer = QTimer()
        self.fatigue_test_timer.timeout.connect(self.perform_fatigue_test)
        self.fatigue_test_timer.start(1000)  # æ¯ç§’è¿›è¡Œä¸€æ¬¡æµ‹è¯•
        
        self.fatigue_results_text.setText(f"å¼€å§‹ç–²åŠ³æ•ˆåº”æµ‹è¯•...\næµ‹è¯•å‘¨æœŸ: {test_cycles}\nå¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    def stop_fatigue_test(self):
        """åœæ­¢ç–²åŠ³æ•ˆåº”æµ‹è¯•"""
        if hasattr(self, 'fatigue_test_timer'):
            self.fatigue_test_timer.stop()
        
        self.start_fatigue_test_btn.setEnabled(True)
        self.stop_fatigue_test_btn.setEnabled(False)
        
        # æ‰§è¡Œç–²åŠ³æ•ˆåº”åˆ†æ
        if self.fatigue_cycle_data and len(self.fatigue_cycle_data) > 5:
            fatigue_array = np.array(self.fatigue_cycle_data)
            fatigue_results = self.fatigue_analyzer.analyze_fatigue_effects(fatigue_array, range(len(self.fatigue_cycle_data)))
            self.display_fatigue_results(fatigue_results)
        else:
            self.fatigue_results_text.setText("æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç–²åŠ³æ•ˆåº”åˆ†æ")
    
    def perform_fatigue_test(self):
        """æ‰§è¡Œç–²åŠ³æ•ˆåº”æµ‹è¯•"""
        if self.current_fatigue_cycle >= self.max_fatigue_cycles:
            self.stop_fatigue_test()
            return
        
        # æ”¶é›†ä¸€ä¸ªå‘¨æœŸçš„æ•°æ®
        cycle_data = []
        cycle_start_time = datetime.now()
        
        # æ¨¡æ‹Ÿä¸€ä¸ªå®Œæ•´çš„åŠ è½½-å¸è½½å‘¨æœŸ
        for i in range(20):  # 20ä¸ªæ•°æ®ç‚¹ä»£è¡¨ä¸€ä¸ªå‘¨æœŸ
            if hasattr(self.parent(), 'get_current_sensor_data'):
                current_data = self.parent().get_current_sensor_data()
                if current_data is not None:
                    cycle_data.append(current_data.copy())
            
            # æ¨¡æ‹Ÿæ—¶é—´å»¶è¿Ÿ
            import time
            time.sleep(0.05)  # 50mså»¶è¿Ÿ
        
        if cycle_data:
            self.fatigue_cycle_data.append(cycle_data)
            self.current_fatigue_cycle += 1
        
        # æ›´æ–°çŠ¶æ€
        status_text = f"ç–²åŠ³æµ‹è¯•è¿›è¡Œä¸­...\nå·²å®Œæˆå‘¨æœŸ: {self.current_fatigue_cycle}/{self.max_fatigue_cycles}\nå½“å‰å‘¨æœŸ: {cycle_start_time.strftime('%H:%M:%S')}"
        self.fatigue_results_text.setText(status_text)
    
    def save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        if not self.time_series_data and not self.response_test_data and not self.fatigue_cycle_data:
            QMessageBox.warning(self, "è­¦å‘Š", "æ²¡æœ‰åˆ†æç»“æœå¯ä¿å­˜")
            return
        
        filename, _ = QFileDialog.getSaveFileName(
            self, "ä¿å­˜æ—¶é—´ä¸€è‡´æ€§åˆ†æç»“æœ", "", "JSONæ–‡ä»¶ (*.json);;CSVæ–‡ä»¶ (*.csv)"
        )
        
        if filename:
            try:
                results = {
                    'analysis_time': datetime.now().isoformat(),
                    'drift_analysis': {},
                    'response_analysis': {},
                    'fatigue_analysis': {}
                }
                
                # ä¿å­˜æ¼‚ç§»åˆ†æç»“æœ
                if self.time_series_data:
                    time_series_array = np.array(self.time_series_data)
                    drift_results = self.drift_analyzer.analyze_temporal_drift(time_series_array, self.time_stamps)
                    results['drift_analysis'] = {
                        'summary_stats': drift_results.get('summary_stats', {}),
                        'drift_rates': drift_results.get('drift_rates', {}).tolist() if isinstance(drift_results.get('drift_rates'), np.ndarray) else {},
                        'anomaly_count': len(drift_results.get('anomaly_points', []))
                    }
                
                # ä¿å­˜å“åº”æ—¶é—´åˆ†æç»“æœ
                if self.response_test_data:
                    response_array = np.array(self.response_test_data)
                    response_results = self.response_analyzer.analyze_response_time(
                        response_array, self.response_test_timestamps, self.pressure_events
                    )
                    results['response_analysis'] = {
                        'summary_stats': response_results.get('summary_stats', {}),
                        'response_consistency': response_results.get('response_consistency', {}),
                        'anomaly_count': len(response_results.get('response_anomalies', []))
                    }
                
                # ä¿å­˜ç–²åŠ³æ•ˆåº”åˆ†æç»“æœ
                if self.fatigue_cycle_data:
                    fatigue_array = np.array(self.fatigue_cycle_data)
                    fatigue_results = self.fatigue_analyzer.analyze_fatigue_effects(fatigue_array, range(len(self.fatigue_cycle_data)))
                    results['fatigue_analysis'] = {
                        'summary_stats': fatigue_results.get('summary_stats', {}),
                        'sensitivity_decay_count': len(fatigue_results.get('sensitivity_decay', {})),
                        'stability_changes_count': len(fatigue_results.get('stability_changes', {}))
                    }
                
                # ä¿å­˜åˆ°æ–‡ä»¶
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(results, f, indent=2, ensure_ascii=False)
                
                QMessageBox.information(self, "æˆåŠŸ", f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {filename}")
                
            except Exception as e:
                QMessageBox.critical(self, "é”™è¯¯", f"ä¿å­˜å¤±è´¥: {e}")
    
    def clear_data(self):
        """æ¸…ç©ºæ•°æ®"""
        self.time_series_data = None
        self.time_stamps = []
        self.pressure_events = []
        self.response_test_data = []
        self.response_test_timestamps = []
        self.fatigue_cycle_data = []
        
        # æ¸…ç©ºæ˜¾ç¤º
        self.drift_results_text.clear()
        self.response_results_text.clear()
        self.fatigue_results_text.clear()
        
        # é‡ç½®æŒ‰é’®çŠ¶æ€
        self.save_results_btn.setEnabled(False)
        
        QMessageBox.information(self, "æ¸…ç©ºå®Œæˆ", "æ‰€æœ‰æ•°æ®å·²æ¸…ç©º")


class TemporalCalibrationSystem:
    """æ—¶é—´æ ¡æ­£ç³»ç»Ÿ"""
    
    def __init__(self):
        self.drift_compensation = None
        self.response_compensation = None
        self.fatigue_compensation = None
        
    def generate_drift_compensation(self, drift_analysis_results):
        """ç”Ÿæˆæ¼‚ç§»è¡¥å¿"""
        drift_rates = drift_analysis_results.get('drift_rates')
        if drift_rates is None:
            return None
        
        # åˆ›å»ºæ¼‚ç§»è¡¥å¿æ˜ å°„
        compensation_map = np.ones_like(drift_rates)
        
        # å¯¹æ¯ä¸ªä¼ æ„Ÿå™¨ç‚¹åº”ç”¨æ¼‚ç§»è¡¥å¿
        for i in range(drift_rates.shape[0]):
            for j in range(drift_rates.shape[1]):
                drift_rate = drift_rates[i, j]
                
                # å¦‚æœæ¼‚ç§»ç‡æ˜¾è‘—ï¼Œåˆ›å»ºè¡¥å¿å‡½æ•°
                if abs(drift_rate) > 1e-6:
                    # çº¿æ€§è¡¥å¿ï¼šcompensation = 1 - drift_rate * time
                    compensation_map[i, j] = 1.0 - drift_rate * 3600  # 1å°æ—¶åçš„è¡¥å¿
        
        return compensation_map
    
    def generate_response_compensation(self, response_analysis_results):
        """ç”Ÿæˆå“åº”æ—¶é—´è¡¥å¿"""
        rise_times = response_analysis_results.get('rise_times', {})
        fall_times = response_analysis_results.get('fall_times', {})
        
        if not rise_times or not fall_times:
            return None
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        all_rise_times = []
        all_fall_times = []
        
        for event_key in rise_times:
            rise_data = rise_times[event_key]
            fall_data = fall_times[event_key]
            
            valid_rise = rise_data[rise_data > 0]
            valid_fall = fall_data[fall_data > 0]
            
            all_rise_times.extend(valid_rise.flatten())
            all_fall_times.extend(valid_fall.flatten())
        
        if not all_rise_times or not all_fall_times:
            return None
        
        avg_rise_time = np.mean(all_rise_times)
        avg_fall_time = np.mean(all_fall_times)
        
        # åˆ›å»ºå“åº”æ—¶é—´è¡¥å¿å‚æ•°
        compensation_params = {
            'avg_rise_time': avg_rise_time,
            'avg_fall_time': avg_fall_time,
            'rise_time_std': np.std(all_rise_times),
            'fall_time_std': np.std(all_fall_times)
        }
        
        return compensation_params
    
    def generate_fatigue_compensation(self, fatigue_analysis_results):
        """ç”Ÿæˆç–²åŠ³æ•ˆåº”è¡¥å¿"""
        sensitivity_decay = fatigue_analysis_results.get('sensitivity_decay', {})
        stability_changes = fatigue_analysis_results.get('stability_changes', {})
        
        if not sensitivity_decay and not stability_changes:
            return None
        
        # åˆ›å»ºç–²åŠ³è¡¥å¿æ˜ å°„
        height, width = 64, 64  # å‡è®¾ä¼ æ„Ÿå™¨å°ºå¯¸
        fatigue_compensation = np.ones((height, width))
        
        # åº”ç”¨æ•æ„Ÿåº¦è¡°å‡è¡¥å¿
        for (i, j), decay_data in sensitivity_decay.items():
            decay_rate = decay_data.get('decay_rate', 0)
            if decay_rate > 0.05:  # 5%ä»¥ä¸Šè¡°å‡æ‰è¡¥å¿
                fatigue_compensation[i, j] = 1.0 + decay_rate
        
        # åº”ç”¨ç¨³å®šæ€§å˜åŒ–è¡¥å¿
        for (i, j), stability_data in stability_changes.items():
            stability_trend = stability_data.get('stability_trend', 0)
            if stability_trend > 0.01:  # ç¨³å®šæ€§æ¶åŒ–æ—¶è¡¥å¿
                fatigue_compensation[i, j] *= (1.0 + stability_trend)
        
        return fatigue_compensation
    
    def apply_temporal_correction(self, raw_data, time_elapsed, pressure_event=None):
        """åº”ç”¨æ—¶é—´æ ¡æ­£"""
        corrected_data = raw_data.copy()
        
        # 1. åº”ç”¨æ¼‚ç§»è¡¥å¿
        if self.drift_compensation is not None:
            drift_factor = 1.0 - self.drift_compensation * time_elapsed
            corrected_data *= drift_factor
        
        # 2. åº”ç”¨å“åº”æ—¶é—´è¡¥å¿
        if self.response_compensation is not None and pressure_event is not None:
            # æ ¹æ®å‹åŠ›äº‹ä»¶çš„æ—¶é—´è°ƒæ•´å“åº”
            event_duration = (pressure_event['end_time'] - pressure_event['start_time']).total_seconds()
            if event_duration < self.response_compensation['avg_rise_time']:
                # å“åº”æ—¶é—´è¡¥å¿
                correction_factor = event_duration / self.response_compensation['avg_rise_time']
                corrected_data *= correction_factor
        
        # 3. åº”ç”¨ç–²åŠ³è¡¥å¿
        if self.fatigue_compensation is not None:
            corrected_data *= self.fatigue_compensation
        
        return corrected_data


# ä½¿ç”¨ç¤ºä¾‹
def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    import sys
    from PyQt5.QtWidgets import QApplication
    
    app = QApplication(sys.argv)
    
    # åˆ›å»ºæ—¶é—´ä¸€è‡´æ€§åˆ†æç•Œé¢
    temporal_widget = TemporalConsistencyWidget()
    temporal_widget.show()
    
    sys.exit(app.exec_())


if __name__ == "__main__":
    main()